{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56572134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "from utils.options import args_parser\n",
    "from utils.train_utils import get_data, get_model\n",
    "from models.Update import DatasetSplit\n",
    "from models.test import test_img_local, test_img_local_all, test_img_global\n",
    "\n",
    "import pdb\n",
    "import easydict\n",
    "\n",
    "import sys\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "# Seed\n",
    "torch.manual_seed(1)#args.running_idx=args.seed\n",
    "torch.cuda.manual_seed(1)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.backends.cudnn.benchmark=False\n",
    "np.random.seed(1)\n",
    "random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6515deb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean(data):\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "def calculate_variance(data):\n",
    "    mean = calculate_mean(data)\n",
    "    squared_diff = [(x - mean) ** 2 for x in data]\n",
    "    variance = sum(squared_diff) / len(data)\n",
    "    return variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "268c1648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Class 1 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1009, 0.1003,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 2 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1012, 0.0979, 0.0956, 0.0953, 0.0968, 0.1032, 0.1028, 0.1013, 0.1002,\n",
      "        0.1058], device='cuda:2')\n",
      "Class 3 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0982, 0.0958, 0.0954, 0.0967, 0.1033, 0.1028, 0.1007, 0.1004,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 4 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0981, 0.0957, 0.0954, 0.0967, 0.1033, 0.1028, 0.1010, 0.1003,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 5 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0982, 0.0958, 0.0954, 0.0966, 0.1034, 0.1028, 0.1005, 0.1004,\n",
      "        0.1053], device='cuda:2')\n",
      "Class 6 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0980, 0.0957, 0.0954, 0.0966, 0.1034, 0.1028, 0.1010, 0.1002,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 7 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0958, 0.0954, 0.0967, 0.1033, 0.1028, 0.1008, 0.1003,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 8 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0980, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1012, 0.1002,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 9 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0956, 0.0954, 0.0967, 0.1033, 0.1028, 0.1008, 0.1004,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 10 - Accuracy: 100.00%\n",
      "Success Probability Vector:\n",
      "tensor([0.1012, 0.0979, 0.0955, 0.0953, 0.0969, 0.1032, 0.1028, 0.1012, 0.1002,\n",
      "        0.1057], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "0.1\n",
      "0.09000000000000001\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1000]\n",
      "[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 0]\n"
     ]
    }
   ],
   "source": [
    "model = 'vgg' # cnn, mobile\n",
    "dataset = 'cifar10' # cifar10, cifar100 \n",
    "num_classes = 10 # 10, 100\n",
    "momentum = 0.90\n",
    "wd = 1e-5\n",
    "server_data_ratio=0.0\n",
    "\n",
    "\n",
    "for shard_per_user in [2]:\n",
    "    for frac in [0.1]:\n",
    "        for local_ep in [15]:\n",
    "            for local_upt_part, aggr_part in [('full', 'full')]:\n",
    "                args = easydict.EasyDict({'epochs': local_ep,\n",
    "                                          'num_users': 100,\n",
    "                                          'shard_per_user': shard_per_user,\n",
    "                                          'server_data_ratio': server_data_ratio,\n",
    "                                          'frac': frac,\n",
    "                                          'local_ep': local_ep,\n",
    "                                          'local_bs': 500,\n",
    "                                          'bs': 50,\n",
    "                                          'lr': 0.01,\n",
    "                                          'momentum': momentum,\n",
    "                                          'wd': wd,\n",
    "                                          'model': model,\n",
    "                                          \n",
    "\n",
    "                                          'dataset': dataset,\n",
    "                                          'iid': False,\n",
    "                                          'num_classes': num_classes,\n",
    "                                          'gpu': 2,\n",
    "                                          'verbose': False,\n",
    "                                          'seed': 1,\n",
    "                                          'test_freq': 1,\n",
    "                                          'load_fed': '',\n",
    "                                          'results_save': 'run1',\n",
    "                                          'local_upt_part': local_upt_part,\n",
    "                                          'aggr_part': aggr_part,\n",
    "                                          'feature_norm': 1,\n",
    "                                          'fn': False,\n",
    "                                          'hetero_option': \"shard\"\n",
    "                                          })\n",
    "\n",
    "                # parse args\n",
    "                args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "                base_dir = './save/full_and_body/{}_iid{}_num{}_C{}_le{}_m{}_wd{}_round_320/shard{}_new/decay_0.1/fn_{}/seed_0/FedAvg'.format(\n",
    "                    args.model, args.iid, args.num_users, args.frac, args.local_ep, args.momentum, args.wd,args.shard_per_user, args.fn)\n",
    "                algo_dir = 'local_upt_{}_lr_{}'.format(args.local_upt_part, args.lr)\n",
    "\n",
    "\n",
    "                dataset_train, dataset_test, dict_users_train, dict_users_test = get_data(args)\n",
    "\n",
    "                test_dataloader = DataLoader(dataset_test, batch_size=args.bs, shuffle=False)\n",
    "\n",
    "\n",
    "                # build model\n",
    "                model = get_model(args)\n",
    "                model_save_path = './full_initial_model.pt'\n",
    "                model.load_state_dict(torch.load(model_save_path, map_location=args.device), strict=True)\n",
    "\n",
    "                model.eval()\n",
    "\n",
    "\n",
    "                # 클래스별로 예측 성공한 데이터와 예측 실패한 데이터의 개수를 저장할 리스트를 생성합니다.\n",
    "                success_counts = [0 for _ in range(10)]\n",
    "                failure_counts = [0 for _ in range(10)]\n",
    "\n",
    "                # 클래스별로 softmax 확률을 누적할 리스트를 생성합니다.\n",
    "                success_prob_sums = [torch.zeros(10).to(args.device) for _ in range(10)]\n",
    "                failure_prob_sums = [torch.zeros(10).to(args.device) for _ in range(10)]\n",
    "\n",
    "                # 클래스별로 정확한 예측 수를 저장할 리스트를 생성합니다.\n",
    "                accuracies = [0 for _ in range(10)]\n",
    "\n",
    "\n",
    "                # 각 데이터의 예측 결과를 확인하고 클래스별로 softmax 확률을 누적합니다.\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in test_dataloader:\n",
    "                        if args.gpu != -1:\n",
    "                            images, labels = images.to(args.device), labels.to(args.device)\n",
    "\n",
    "                        outputs = model(images)\n",
    "                        softmax_probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "                        predicted_labels = torch.argmax(softmax_probs, dim=1)\n",
    "\n",
    "                        for i in range(len(labels)):\n",
    "                            label = labels[i].item()\n",
    "                            predicted_label = predicted_labels[i].item()\n",
    "                            prob_vector = softmax_probs[i]\n",
    "\n",
    "                            if predicted_label == label:\n",
    "                                # 예측 성공한 경우\n",
    "                                success_counts[label] += 1\n",
    "                                success_prob_sums[label] += prob_vector\n",
    "                                accuracies[label] += 1\n",
    "                            else:\n",
    "                                # 예측 실패한 경우\n",
    "                                failure_counts[label] += 1\n",
    "                                failure_prob_sums[label] += prob_vector\n",
    "\n",
    "\n",
    "            # 클래스별로 평균 softmax 확률 벡터를 계산합니다.\n",
    "            success_prob_vectors = [success_prob_sums[i] / success_counts[i] for i in range(10)]\n",
    "            failure_prob_vectors = [failure_prob_sums[i] / failure_counts[i] for i in range(10)]\n",
    "            classwise_accuracy=[]\n",
    "\n",
    "            # 결과 출력\n",
    "            for i in range(10):\n",
    "                print(f\"Class {i+1} - Accuracy: {success_counts[i]/(success_counts[i]+failure_counts[i]):.2%}\")\n",
    "                classwise_accuracy.append(success_counts[i]/(success_counts[i]+failure_counts[i]))\n",
    "                print(\"Success Probability Vector:\")\n",
    "                print(success_prob_vectors[i])\n",
    "                print(\"Failure Probability Vector:\")\n",
    "                print(failure_prob_vectors[i])\n",
    "        print(classwise_accuracy)\n",
    "        print(sum(classwise_accuracy) / len(classwise_accuracy))\n",
    "        print(calculate_variance(classwise_accuracy))\n",
    "        print(success_counts) \n",
    "        print(failure_counts) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80dd6e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Class 1 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1009, 0.1003,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 2 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1012, 0.0979, 0.0956, 0.0953, 0.0968, 0.1032, 0.1028, 0.1013, 0.1002,\n",
      "        0.1057], device='cuda:2')\n",
      "Class 3 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0982, 0.0958, 0.0954, 0.0967, 0.1033, 0.1028, 0.1007, 0.1004,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 4 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0981, 0.0957, 0.0954, 0.0967, 0.1033, 0.1028, 0.1010, 0.1003,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 5 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0982, 0.0958, 0.0954, 0.0966, 0.1034, 0.1028, 0.1006, 0.1004,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 6 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0980, 0.0957, 0.0954, 0.0966, 0.1034, 0.1028, 0.1010, 0.1002,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 7 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0957, 0.0954, 0.0967, 0.1033, 0.1028, 0.1008, 0.1003,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 8 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0980, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1011, 0.1002,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 9 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1008, 0.1004,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 10 - Accuracy: 100.00%\n",
      "Success Probability Vector:\n",
      "tensor([0.1012, 0.0979, 0.0956, 0.0953, 0.0969, 0.1032, 0.1028, 0.1012, 0.1002,\n",
      "        0.1057], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "0.1\n",
      "0.09000000000000001\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 5000]\n",
      "[5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 0]\n"
     ]
    }
   ],
   "source": [
    "model = 'vgg' # cnn, mobile\n",
    "dataset = 'cifar10' # cifar10, cifar100 \n",
    "num_classes = 10 # 10, 100\n",
    "momentum = 0.90\n",
    "wd = 1e-5\n",
    "server_data_ratio=0.0\n",
    "\n",
    "\n",
    "for shard_per_user in [2]:\n",
    "    for frac in [0.1]:\n",
    "        for local_ep in [15]:\n",
    "            for local_upt_part, aggr_part in [('full', 'full')]:\n",
    "                args = easydict.EasyDict({'epochs': local_ep,\n",
    "                                          'num_users': 100,\n",
    "                                          'shard_per_user': shard_per_user,\n",
    "                                          'server_data_ratio': server_data_ratio,\n",
    "                                          'frac': frac,\n",
    "                                          'local_ep': local_ep,\n",
    "                                          'local_bs': 500,\n",
    "                                          'bs': 50,\n",
    "                                          'lr': 0.01,\n",
    "                                          'momentum': momentum,\n",
    "                                          'wd': wd,\n",
    "                                          'model': model,\n",
    "                                          \n",
    "\n",
    "                                          'dataset': dataset,\n",
    "                                          'iid': False,\n",
    "                                          'num_classes': num_classes,\n",
    "                                          'gpu': 2,\n",
    "                                          'verbose': False,\n",
    "                                          'seed': 1,\n",
    "                                          'test_freq': 1,\n",
    "                                          'load_fed': '',\n",
    "                                          'results_save': 'run1',\n",
    "                                          'local_upt_part': local_upt_part,\n",
    "                                          'aggr_part': aggr_part,\n",
    "                                          'feature_norm': 1,\n",
    "                                          'fn': False,\n",
    "                                          'hetero_option': \"shard\"\n",
    "                                          })\n",
    "\n",
    "                # parse args\n",
    "                args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "                base_dir = './save/full_and_body/{}_iid{}_num{}_C{}_le{}_m{}_wd{}_round_320/shard{}_new/decay_0.1/fn_{}/seed_0/FedAvg'.format(\n",
    "                    args.model, args.iid, args.num_users, args.frac, args.local_ep, args.momentum, args.wd,args.shard_per_user, args.fn)\n",
    "                algo_dir = 'local_upt_{}_lr_{}'.format(args.local_upt_part, args.lr)\n",
    "\n",
    "\n",
    "                dataset_train, dataset_test, dict_users_train, dict_users_test = get_data(args)\n",
    "\n",
    "                test_dataloader = DataLoader(dataset_train, batch_size=args.bs, shuffle=False)\n",
    "\n",
    "\n",
    "                # build model\n",
    "                model = get_model(args)\n",
    "                model_save_path = './full_initial_model.pt'\n",
    "                model.load_state_dict(torch.load(model_save_path, map_location=args.device), strict=True)\n",
    "\n",
    "                model.eval()\n",
    "\n",
    "\n",
    "                # 클래스별로 예측 성공한 데이터와 예측 실패한 데이터의 개수를 저장할 리스트를 생성합니다.\n",
    "                success_counts = [0 for _ in range(10)]\n",
    "                failure_counts = [0 for _ in range(10)]\n",
    "\n",
    "                # 클래스별로 softmax 확률을 누적할 리스트를 생성합니다.\n",
    "                success_prob_sums = [torch.zeros(10).to(args.device) for _ in range(10)]\n",
    "                failure_prob_sums = [torch.zeros(10).to(args.device) for _ in range(10)]\n",
    "\n",
    "                # 클래스별로 정확한 예측 수를 저장할 리스트를 생성합니다.\n",
    "                accuracies = [0 for _ in range(10)]\n",
    "\n",
    "\n",
    "                # 각 데이터의 예측 결과를 확인하고 클래스별로 softmax 확률을 누적합니다.\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in test_dataloader:\n",
    "                        if args.gpu != -1:\n",
    "                            images, labels = images.to(args.device), labels.to(args.device)\n",
    "\n",
    "                        outputs = model(images)\n",
    "                        softmax_probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "                        predicted_labels = torch.argmax(softmax_probs, dim=1)\n",
    "\n",
    "                        for i in range(len(labels)):\n",
    "                            label = labels[i].item()\n",
    "                            predicted_label = predicted_labels[i].item()\n",
    "                            prob_vector = softmax_probs[i]\n",
    "\n",
    "                            if predicted_label == label:\n",
    "                                # 예측 성공한 경우\n",
    "                                success_counts[label] += 1\n",
    "                                success_prob_sums[label] += prob_vector\n",
    "                                accuracies[label] += 1\n",
    "                            else:\n",
    "                                # 예측 실패한 경우\n",
    "                                failure_counts[label] += 1\n",
    "                                failure_prob_sums[label] += prob_vector\n",
    "\n",
    "\n",
    "            # 클래스별로 평균 softmax 확률 벡터를 계산합니다.\n",
    "            success_prob_vectors = [success_prob_sums[i] / success_counts[i] for i in range(10)]\n",
    "            failure_prob_vectors = [failure_prob_sums[i] / failure_counts[i] for i in range(10)]\n",
    "            classwise_accuracy=[]\n",
    "\n",
    "            # 결과 출력\n",
    "            for i in range(10):\n",
    "                print(f\"Class {i+1} - Accuracy: {success_counts[i]/(success_counts[i]+failure_counts[i]):.2%}\")\n",
    "                classwise_accuracy.append(success_counts[i]/(success_counts[i]+failure_counts[i]))\n",
    "                print(\"Success Probability Vector:\")\n",
    "                print(success_prob_vectors[i])\n",
    "                print(\"Failure Probability Vector:\")\n",
    "                print(failure_prob_vectors[i])\n",
    "        print(classwise_accuracy)\n",
    "        print(sum(classwise_accuracy) / len(classwise_accuracy))\n",
    "        print(calculate_variance(classwise_accuracy))\n",
    "        print(success_counts) \n",
    "        print(failure_counts) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85976c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Class 1 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1009, 0.1003,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 2 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1012, 0.0979, 0.0956, 0.0953, 0.0968, 0.1032, 0.1028, 0.1013, 0.1002,\n",
      "        0.1058], device='cuda:2')\n",
      "Class 3 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0982, 0.0958, 0.0954, 0.0967, 0.1033, 0.1028, 0.1007, 0.1004,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 4 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0981, 0.0957, 0.0954, 0.0967, 0.1033, 0.1028, 0.1010, 0.1003,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 5 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0982, 0.0958, 0.0954, 0.0966, 0.1034, 0.1028, 0.1005, 0.1004,\n",
      "        0.1053], device='cuda:2')\n",
      "Class 6 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0980, 0.0957, 0.0954, 0.0966, 0.1034, 0.1028, 0.1010, 0.1002,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 7 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0958, 0.0954, 0.0967, 0.1033, 0.1028, 0.1008, 0.1003,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 8 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0980, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1012, 0.1002,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 9 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0956, 0.0954, 0.0967, 0.1033, 0.1028, 0.1008, 0.1004,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 10 - Accuracy: 100.00%\n",
      "Success Probability Vector:\n",
      "tensor([0.1012, 0.0979, 0.0955, 0.0953, 0.0969, 0.1032, 0.1028, 0.1012, 0.1002,\n",
      "        0.1057], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "0.1\n",
      "0.09000000000000001\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1000]\n",
      "[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 0]\n"
     ]
    }
   ],
   "source": [
    "model = 'vgg' # cnn, mobile\n",
    "dataset = 'cifar10' # cifar10, cifar100 \n",
    "num_classes = 10 # 10, 100\n",
    "momentum = 0.90\n",
    "wd = 1e-5\n",
    "server_data_ratio=0.0\n",
    "\n",
    "\n",
    "for shard_per_user in [2]:\n",
    "    for frac in [0.1]:\n",
    "        for local_ep in [15]:\n",
    "            for local_upt_part, aggr_part in [('full', 'full')]:\n",
    "                args = easydict.EasyDict({'epochs': local_ep,\n",
    "                                          'num_users': 100,\n",
    "                                          'shard_per_user': shard_per_user,\n",
    "                                          'server_data_ratio': server_data_ratio,\n",
    "                                          'frac': frac,\n",
    "                                          'local_ep': local_ep,\n",
    "                                          'local_bs': 500,\n",
    "                                          'bs': 50,\n",
    "                                          'lr': 0.01,\n",
    "                                          'momentum': momentum,\n",
    "                                          'wd': wd,\n",
    "                                          'model': model,\n",
    "                                          \n",
    "\n",
    "                                          'dataset': dataset,\n",
    "                                          'iid': False,\n",
    "                                          'num_classes': num_classes,\n",
    "                                          'gpu': 2,\n",
    "                                          'verbose': False,\n",
    "                                          'seed': 1,\n",
    "                                          'test_freq': 1,\n",
    "                                          'load_fed': '',\n",
    "                                          'results_save': 'run1',\n",
    "                                          'local_upt_part': local_upt_part,\n",
    "                                          'aggr_part': aggr_part,\n",
    "                                          'feature_norm': 1,\n",
    "                                          'fn': False,\n",
    "                                          'hetero_option': \"shard\"\n",
    "                                          })\n",
    "\n",
    "                # parse args\n",
    "                args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "                base_dir = './save/full_and_body/{}_iid{}_num{}_C{}_le{}_m{}_wd{}_round_320/shard{}_new/decay_0.1/fn_{}/seed_0/FedAvg'.format(\n",
    "                    args.model, args.iid, args.num_users, args.frac, args.local_ep, args.momentum, args.wd,args.shard_per_user, args.fn)\n",
    "                algo_dir = 'local_upt_{}_lr_{}'.format(args.local_upt_part, args.lr)\n",
    "\n",
    "\n",
    "                dataset_train, dataset_test, dict_users_train, dict_users_test = get_data(args)\n",
    "\n",
    "                test_dataloader = DataLoader(dataset_test, batch_size=args.bs, shuffle=False)\n",
    "\n",
    "\n",
    "                # build model\n",
    "                model = get_model(args)\n",
    "#                 model_save_path = './full_initial_model.pt'\n",
    "                model.load_state_dict(torch.load(model_save_path, map_location=args.device), strict=True)\n",
    "\n",
    "                model.eval()\n",
    "\n",
    "\n",
    "                # 클래스별로 예측 성공한 데이터와 예측 실패한 데이터의 개수를 저장할 리스트를 생성합니다.\n",
    "                success_counts = [0 for _ in range(10)]\n",
    "                failure_counts = [0 for _ in range(10)]\n",
    "\n",
    "                # 클래스별로 softmax 확률을 누적할 리스트를 생성합니다.\n",
    "                success_prob_sums = [torch.zeros(10).to(args.device) for _ in range(10)]\n",
    "                failure_prob_sums = [torch.zeros(10).to(args.device) for _ in range(10)]\n",
    "\n",
    "                # 클래스별로 정확한 예측 수를 저장할 리스트를 생성합니다.\n",
    "                accuracies = [0 for _ in range(10)]\n",
    "\n",
    "\n",
    "                # 각 데이터의 예측 결과를 확인하고 클래스별로 softmax 확률을 누적합니다.\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in test_dataloader:\n",
    "                        if args.gpu != -1:\n",
    "                            images, labels = images.to(args.device), labels.to(args.device)\n",
    "\n",
    "                        outputs = model(images)\n",
    "                        softmax_probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "                        predicted_labels = torch.argmax(softmax_probs, dim=1)\n",
    "\n",
    "                        for i in range(len(labels)):\n",
    "                            label = labels[i].item()\n",
    "                            predicted_label = predicted_labels[i].item()\n",
    "                            prob_vector = softmax_probs[i]\n",
    "\n",
    "                            if predicted_label == label:\n",
    "                                # 예측 성공한 경우\n",
    "                                success_counts[label] += 1\n",
    "                                success_prob_sums[label] += prob_vector\n",
    "                                accuracies[label] += 1\n",
    "                            else:\n",
    "                                # 예측 실패한 경우\n",
    "                                failure_counts[label] += 1\n",
    "                                failure_prob_sums[label] += prob_vector\n",
    "\n",
    "\n",
    "            # 클래스별로 평균 softmax 확률 벡터를 계산합니다.\n",
    "            success_prob_vectors = [success_prob_sums[i] / success_counts[i] for i in range(10)]\n",
    "            failure_prob_vectors = [failure_prob_sums[i] / failure_counts[i] for i in range(10)]\n",
    "            classwise_accuracy=[]\n",
    "\n",
    "            # 결과 출력\n",
    "            for i in range(10):\n",
    "                print(f\"Class {i+1} - Accuracy: {success_counts[i]/(success_counts[i]+failure_counts[i]):.2%}\")\n",
    "                classwise_accuracy.append(success_counts[i]/(success_counts[i]+failure_counts[i]))\n",
    "                print(\"Success Probability Vector:\")\n",
    "                print(success_prob_vectors[i])\n",
    "                print(\"Failure Probability Vector:\")\n",
    "                print(failure_prob_vectors[i])\n",
    "        print(classwise_accuracy)\n",
    "        print(sum(classwise_accuracy) / len(classwise_accuracy))\n",
    "        print(calculate_variance(classwise_accuracy))\n",
    "        print(success_counts) \n",
    "        print(failure_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7addb109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Class 1 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1009, 0.1003,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 2 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1012, 0.0979, 0.0956, 0.0953, 0.0968, 0.1032, 0.1028, 0.1013, 0.1002,\n",
      "        0.1058], device='cuda:2')\n",
      "Class 3 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0982, 0.0958, 0.0954, 0.0967, 0.1033, 0.1028, 0.1007, 0.1004,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 4 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0981, 0.0957, 0.0954, 0.0967, 0.1033, 0.1028, 0.1010, 0.1003,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 5 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0982, 0.0958, 0.0954, 0.0966, 0.1034, 0.1028, 0.1005, 0.1004,\n",
      "        0.1053], device='cuda:2')\n",
      "Class 6 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0980, 0.0957, 0.0954, 0.0966, 0.1034, 0.1028, 0.1010, 0.1002,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 7 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0958, 0.0954, 0.0967, 0.1033, 0.1028, 0.1008, 0.1003,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 8 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0980, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1012, 0.1002,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 9 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0956, 0.0954, 0.0967, 0.1033, 0.1028, 0.1008, 0.1004,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 10 - Accuracy: 100.00%\n",
      "Success Probability Vector:\n",
      "tensor([0.1012, 0.0979, 0.0955, 0.0953, 0.0969, 0.1032, 0.1028, 0.1012, 0.1002,\n",
      "        0.1057], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "0.1\n",
      "0.09000000000000001\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1000]\n",
      "[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 0]\n"
     ]
    }
   ],
   "source": [
    "model = 'vgg' # cnn, mobile\n",
    "dataset = 'cifar10' # cifar10, cifar100 \n",
    "num_classes = 10 # 10, 100\n",
    "momentum = 0.90\n",
    "wd = 1e-5\n",
    "server_data_ratio=0.0\n",
    "\n",
    "\n",
    "for shard_per_user in [2]:\n",
    "    for frac in [0.1]:\n",
    "        for local_ep in [15]:\n",
    "            for local_upt_part, aggr_part in [('full', 'full')]:\n",
    "                args = easydict.EasyDict({'epochs': local_ep,\n",
    "                                          'num_users': 100,\n",
    "                                          'shard_per_user': shard_per_user,\n",
    "                                          'server_data_ratio': server_data_ratio,\n",
    "                                          'frac': frac,\n",
    "                                          'local_ep': local_ep,\n",
    "                                          'local_bs': 500,\n",
    "                                          'bs': 50,\n",
    "                                          'lr': 0.01,\n",
    "                                          'momentum': momentum,\n",
    "                                          'wd': wd,\n",
    "                                          'model': model,\n",
    "                                          \n",
    "\n",
    "                                          'dataset': dataset,\n",
    "                                          'iid': False,\n",
    "                                          'num_classes': num_classes,\n",
    "                                          'gpu': 2,\n",
    "                                          'verbose': False,\n",
    "                                          'seed': 1,\n",
    "                                          'test_freq': 1,\n",
    "                                          'load_fed': '',\n",
    "                                          'results_save': 'run1',\n",
    "                                          'local_upt_part': local_upt_part,\n",
    "                                          'aggr_part': aggr_part,\n",
    "                                          'feature_norm': 1,\n",
    "                                          'fn': False,\n",
    "                                          'hetero_option': \"shard\"\n",
    "                                          })\n",
    "\n",
    "                # parse args\n",
    "                args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "                base_dir = './save/full_and_body/{}_iid{}_num{}_C{}_le{}_m{}_wd{}_round_320/shard{}_new/decay_0.1/fn_{}/seed_0/FedAvg'.format(\n",
    "                    args.model, args.iid, args.num_users, args.frac, args.local_ep, args.momentum, args.wd,args.shard_per_user, args.fn)\n",
    "                algo_dir = 'local_upt_{}_lr_{}'.format(args.local_upt_part, args.lr)\n",
    "\n",
    "\n",
    "                dataset_train, dataset_test, dict_users_train, dict_users_test = get_data(args)\n",
    "\n",
    "                test_dataloader = DataLoader(dataset_test, batch_size=args.bs, shuffle=False)\n",
    "\n",
    "\n",
    "                # build model\n",
    "                model = get_model(args)\n",
    "#                 model_save_path = './full_initial_model.pt'\n",
    "                model.load_state_dict(torch.load(model_save_path, map_location=args.device), strict=True)\n",
    "\n",
    "                model.eval()\n",
    "\n",
    "\n",
    "                # 클래스별로 예측 성공한 데이터와 예측 실패한 데이터의 개수를 저장할 리스트를 생성합니다.\n",
    "                success_counts = [0 for _ in range(10)]\n",
    "                failure_counts = [0 for _ in range(10)]\n",
    "\n",
    "                # 클래스별로 softmax 확률을 누적할 리스트를 생성합니다.\n",
    "                success_prob_sums = [torch.zeros(10).to(args.device) for _ in range(10)]\n",
    "                failure_prob_sums = [torch.zeros(10).to(args.device) for _ in range(10)]\n",
    "\n",
    "                # 클래스별로 정확한 예측 수를 저장할 리스트를 생성합니다.\n",
    "                accuracies = [0 for _ in range(10)]\n",
    "\n",
    "\n",
    "                # 각 데이터의 예측 결과를 확인하고 클래스별로 softmax 확률을 누적합니다.\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in test_dataloader:\n",
    "                        if args.gpu != -1:\n",
    "                            images, labels = images.to(args.device), labels.to(args.device)\n",
    "\n",
    "                        outputs = model(images)\n",
    "                        softmax_probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "                        predicted_labels = torch.argmax(softmax_probs, dim=1)\n",
    "\n",
    "                        for i in range(len(labels)):\n",
    "                            label = labels[i].item()\n",
    "                            predicted_label = predicted_labels[i].item()\n",
    "                            prob_vector = softmax_probs[i]\n",
    "\n",
    "                            if predicted_label == label:\n",
    "                                # 예측 성공한 경우\n",
    "                                success_counts[label] += 1\n",
    "                                success_prob_sums[label] += prob_vector\n",
    "                                accuracies[label] += 1\n",
    "                            else:\n",
    "                                # 예측 실패한 경우\n",
    "                                failure_counts[label] += 1\n",
    "                                failure_prob_sums[label] += prob_vector\n",
    "\n",
    "\n",
    "            # 클래스별로 평균 softmax 확률 벡터를 계산합니다.\n",
    "            success_prob_vectors = [success_prob_sums[i] / success_counts[i] for i in range(10)]\n",
    "            failure_prob_vectors = [failure_prob_sums[i] / failure_counts[i] for i in range(10)]\n",
    "            classwise_accuracy=[]\n",
    "\n",
    "            # 결과 출력\n",
    "            for i in range(10):\n",
    "                print(f\"Class {i+1} - Accuracy: {success_counts[i]/(success_counts[i]+failure_counts[i]):.2%}\")\n",
    "                classwise_accuracy.append(success_counts[i]/(success_counts[i]+failure_counts[i]))\n",
    "                print(\"Success Probability Vector:\")\n",
    "                print(success_prob_vectors[i])\n",
    "                print(\"Failure Probability Vector:\")\n",
    "                print(failure_prob_vectors[i])\n",
    "        print(classwise_accuracy)\n",
    "        print(sum(classwise_accuracy) / len(classwise_accuracy))\n",
    "        print(calculate_variance(classwise_accuracy))\n",
    "        print(success_counts) \n",
    "        print(failure_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a32eb210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Class 1 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1009, 0.1003,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 2 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1012, 0.0979, 0.0956, 0.0953, 0.0968, 0.1032, 0.1028, 0.1013, 0.1002,\n",
      "        0.1058], device='cuda:2')\n",
      "Class 3 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0982, 0.0958, 0.0954, 0.0967, 0.1033, 0.1028, 0.1007, 0.1004,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 4 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0981, 0.0957, 0.0954, 0.0967, 0.1033, 0.1028, 0.1010, 0.1003,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 5 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0982, 0.0958, 0.0954, 0.0966, 0.1034, 0.1028, 0.1005, 0.1004,\n",
      "        0.1053], device='cuda:2')\n",
      "Class 6 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0980, 0.0957, 0.0954, 0.0966, 0.1034, 0.1028, 0.1010, 0.1002,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 7 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0958, 0.0954, 0.0967, 0.1033, 0.1028, 0.1008, 0.1003,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 8 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0980, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1012, 0.1002,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 9 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0956, 0.0954, 0.0967, 0.1033, 0.1028, 0.1008, 0.1004,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 10 - Accuracy: 100.00%\n",
      "Success Probability Vector:\n",
      "tensor([0.1012, 0.0979, 0.0955, 0.0953, 0.0969, 0.1032, 0.1028, 0.1012, 0.1002,\n",
      "        0.1057], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "0.1\n",
      "0.09000000000000001\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1000]\n",
      "[1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 0]\n"
     ]
    }
   ],
   "source": [
    "model = 'vgg' # cnn, mobile\n",
    "dataset = 'cifar10' # cifar10, cifar100 \n",
    "num_classes = 10 # 10, 100\n",
    "momentum = 0.90\n",
    "wd = 1e-5\n",
    "server_data_ratio=0.0\n",
    "\n",
    "\n",
    "for shard_per_user in [2]:\n",
    "    for frac in [0.1]:\n",
    "        for local_ep in [15]:\n",
    "            for local_upt_part, aggr_part in [('full', 'full')]:\n",
    "                args = easydict.EasyDict({'epochs': local_ep,\n",
    "                                          'num_users': 100,\n",
    "                                          'shard_per_user': shard_per_user,\n",
    "                                          'server_data_ratio': server_data_ratio,\n",
    "                                          'frac': frac,\n",
    "                                          'local_ep': local_ep,\n",
    "                                          'local_bs': 500,\n",
    "                                          'bs': 50,\n",
    "                                          'lr': 0.01,\n",
    "                                          'momentum': momentum,\n",
    "                                          'wd': wd,\n",
    "                                          'model': model,\n",
    "                                          \n",
    "\n",
    "                                          'dataset': dataset,\n",
    "                                          'iid': False,\n",
    "                                          'num_classes': num_classes,\n",
    "                                          'gpu': 2,\n",
    "                                          'verbose': False,\n",
    "                                          'seed': 1,\n",
    "                                          'test_freq': 1,\n",
    "                                          'load_fed': '',\n",
    "                                          'results_save': 'run1',\n",
    "                                          'local_upt_part': local_upt_part,\n",
    "                                          'aggr_part': aggr_part,\n",
    "                                          'feature_norm': 1,\n",
    "                                          'fn': False,\n",
    "                                          'hetero_option': \"shard\"\n",
    "                                          })\n",
    "\n",
    "                # parse args\n",
    "                args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "                base_dir = './save/full_and_body/{}_iid{}_num{}_C{}_le{}_m{}_wd{}_round_320/shard{}_new/decay_0.1/fn_{}/seed_0/FedAvg'.format(\n",
    "                    args.model, args.iid, args.num_users, args.frac, args.local_ep, args.momentum, args.wd,args.shard_per_user, args.fn)\n",
    "                algo_dir = 'local_upt_{}_lr_{}'.format(args.local_upt_part, args.lr)\n",
    "\n",
    "\n",
    "                dataset_train, dataset_test, dict_users_train, dict_users_test = get_data(args)\n",
    "\n",
    "                test_dataloader = DataLoader(dataset_test, batch_size=args.bs, shuffle=False)\n",
    "\n",
    "\n",
    "                # build model\n",
    "                model = get_model(args)\n",
    "#                 model_save_path = './full_initial_model.pt'\n",
    "                model.load_state_dict(torch.load(model_save_path, map_location=args.device), strict=True)\n",
    "\n",
    "                model.eval()\n",
    "\n",
    "\n",
    "                # 클래스별로 예측 성공한 데이터와 예측 실패한 데이터의 개수를 저장할 리스트를 생성합니다.\n",
    "                success_counts = [0 for _ in range(10)]\n",
    "                failure_counts = [0 for _ in range(10)]\n",
    "\n",
    "                # 클래스별로 softmax 확률을 누적할 리스트를 생성합니다.\n",
    "                success_prob_sums = [torch.zeros(10).to(args.device) for _ in range(10)]\n",
    "                failure_prob_sums = [torch.zeros(10).to(args.device) for _ in range(10)]\n",
    "\n",
    "                # 클래스별로 정확한 예측 수를 저장할 리스트를 생성합니다.\n",
    "                accuracies = [0 for _ in range(10)]\n",
    "\n",
    "\n",
    "                # 각 데이터의 예측 결과를 확인하고 클래스별로 softmax 확률을 누적합니다.\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in test_dataloader:\n",
    "                        if args.gpu != -1:\n",
    "                            images, labels = images.to(args.device), labels.to(args.device)\n",
    "\n",
    "                        outputs = model(images)\n",
    "                        softmax_probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "                        predicted_labels = torch.argmax(softmax_probs, dim=1)\n",
    "\n",
    "                        for i in range(len(labels)):\n",
    "                            label = labels[i].item()\n",
    "                            predicted_label = predicted_labels[i].item()\n",
    "                            prob_vector = softmax_probs[i]\n",
    "\n",
    "                            if predicted_label == label:\n",
    "                                # 예측 성공한 경우\n",
    "                                success_counts[label] += 1\n",
    "                                success_prob_sums[label] += prob_vector\n",
    "                                accuracies[label] += 1\n",
    "                            else:\n",
    "                                # 예측 실패한 경우\n",
    "                                failure_counts[label] += 1\n",
    "                                failure_prob_sums[label] += prob_vector\n",
    "\n",
    "\n",
    "            # 클래스별로 평균 softmax 확률 벡터를 계산합니다.\n",
    "            success_prob_vectors = [success_prob_sums[i] / success_counts[i] for i in range(10)]\n",
    "            failure_prob_vectors = [failure_prob_sums[i] / failure_counts[i] for i in range(10)]\n",
    "            classwise_accuracy=[]\n",
    "\n",
    "            # 결과 출력\n",
    "            for i in range(10):\n",
    "                print(f\"Class {i+1} - Accuracy: {success_counts[i]/(success_counts[i]+failure_counts[i]):.2%}\")\n",
    "                classwise_accuracy.append(success_counts[i]/(success_counts[i]+failure_counts[i]))\n",
    "                print(\"Success Probability Vector:\")\n",
    "                print(success_prob_vectors[i])\n",
    "                print(\"Failure Probability Vector:\")\n",
    "                print(failure_prob_vectors[i])\n",
    "        print(classwise_accuracy)\n",
    "        print(sum(classwise_accuracy) / len(classwise_accuracy))\n",
    "        print(calculate_variance(classwise_accuracy))\n",
    "        print(success_counts) \n",
    "        print(failure_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d8bf348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Class 1 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1009, 0.1003,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 2 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1012, 0.0979, 0.0956, 0.0953, 0.0968, 0.1032, 0.1028, 0.1013, 0.1002,\n",
      "        0.1057], device='cuda:2')\n",
      "Class 3 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0982, 0.0958, 0.0954, 0.0967, 0.1033, 0.1028, 0.1007, 0.1004,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 4 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0981, 0.0957, 0.0954, 0.0967, 0.1033, 0.1028, 0.1010, 0.1003,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 5 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0982, 0.0958, 0.0954, 0.0966, 0.1034, 0.1028, 0.1006, 0.1004,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 6 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0980, 0.0957, 0.0954, 0.0966, 0.1034, 0.1028, 0.1010, 0.1002,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 7 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0957, 0.0954, 0.0967, 0.1033, 0.1028, 0.1008, 0.1003,\n",
      "        0.1054], device='cuda:2')\n",
      "Class 8 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1013, 0.0980, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1011, 0.1002,\n",
      "        0.1056], device='cuda:2')\n",
      "Class 9 - Accuracy: 0.00%\n",
      "Success Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([0.1014, 0.0981, 0.0956, 0.0953, 0.0967, 0.1033, 0.1028, 0.1008, 0.1004,\n",
      "        0.1055], device='cuda:2')\n",
      "Class 10 - Accuracy: 100.00%\n",
      "Success Probability Vector:\n",
      "tensor([0.1012, 0.0979, 0.0956, 0.0953, 0.0969, 0.1032, 0.1028, 0.1012, 0.1002,\n",
      "        0.1057], device='cuda:2')\n",
      "Failure Probability Vector:\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan], device='cuda:2')\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]\n",
      "0.1\n",
      "0.09000000000000001\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 5000]\n",
      "[5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 0]\n"
     ]
    }
   ],
   "source": [
    "model = 'vgg' # cnn, mobile\n",
    "dataset = 'cifar10' # cifar10, cifar100 \n",
    "num_classes = 10 # 10, 100\n",
    "momentum = 0.90\n",
    "wd = 1e-5\n",
    "server_data_ratio=0.0\n",
    "\n",
    "\n",
    "for shard_per_user in [2]:\n",
    "    for frac in [0.1]:\n",
    "        for local_ep in [15]:\n",
    "            for local_upt_part, aggr_part in [('full', 'full')]:\n",
    "                args = easydict.EasyDict({'epochs': local_ep,\n",
    "                                          'num_users': 100,\n",
    "                                          'shard_per_user': shard_per_user,\n",
    "                                          'server_data_ratio': server_data_ratio,\n",
    "                                          'frac': frac,\n",
    "                                          'local_ep': local_ep,\n",
    "                                          'local_bs': 500,\n",
    "                                          'bs': 50,\n",
    "                                          'lr': 0.01,\n",
    "                                          'momentum': momentum,\n",
    "                                          'wd': wd,\n",
    "                                          'model': model,\n",
    "                                          \n",
    "\n",
    "                                          'dataset': dataset,\n",
    "                                          'iid': False,\n",
    "                                          'num_classes': num_classes,\n",
    "                                          'gpu': 2,\n",
    "                                          'verbose': False,\n",
    "                                          'seed': 1,\n",
    "                                          'test_freq': 1,\n",
    "                                          'load_fed': '',\n",
    "                                          'results_save': 'run1',\n",
    "                                          'local_upt_part': local_upt_part,\n",
    "                                          'aggr_part': aggr_part,\n",
    "                                          'feature_norm': 1,\n",
    "                                          'fn': False,\n",
    "                                          'hetero_option': \"shard\"\n",
    "                                          })\n",
    "\n",
    "                # parse args\n",
    "                args.device = torch.device('cuda:{}'.format(args.gpu) if torch.cuda.is_available() and args.gpu != -1 else 'cpu')\n",
    "                base_dir = './save/full_and_body/{}_iid{}_num{}_C{}_le{}_m{}_wd{}_round_320/shard{}_new/decay_0.1/fn_{}/seed_0/FedAvg'.format(\n",
    "                    args.model, args.iid, args.num_users, args.frac, args.local_ep, args.momentum, args.wd,args.shard_per_user, args.fn)\n",
    "                algo_dir = 'local_upt_{}_lr_{}'.format(args.local_upt_part, args.lr)\n",
    "\n",
    "\n",
    "                dataset_train, dataset_test, dict_users_train, dict_users_test = get_data(args)\n",
    "\n",
    "                test_dataloader = DataLoader(dataset_train, batch_size=args.bs, shuffle=False)\n",
    "\n",
    "\n",
    "                # build model\n",
    "                model = get_model(args)\n",
    "#                 model_save_path = './full_initial_model.pt'\n",
    "                model.load_state_dict(torch.load(model_save_path, map_location=args.device), strict=True)\n",
    "\n",
    "                model.eval()\n",
    "\n",
    "\n",
    "                # 클래스별로 예측 성공한 데이터와 예측 실패한 데이터의 개수를 저장할 리스트를 생성합니다.\n",
    "                success_counts = [0 for _ in range(10)]\n",
    "                failure_counts = [0 for _ in range(10)]\n",
    "\n",
    "                # 클래스별로 softmax 확률을 누적할 리스트를 생성합니다.\n",
    "                success_prob_sums = [torch.zeros(10).to(args.device) for _ in range(10)]\n",
    "                failure_prob_sums = [torch.zeros(10).to(args.device) for _ in range(10)]\n",
    "\n",
    "                # 클래스별로 정확한 예측 수를 저장할 리스트를 생성합니다.\n",
    "                accuracies = [0 for _ in range(10)]\n",
    "\n",
    "\n",
    "                # 각 데이터의 예측 결과를 확인하고 클래스별로 softmax 확률을 누적합니다.\n",
    "                with torch.no_grad():\n",
    "                    for images, labels in test_dataloader:\n",
    "                        if args.gpu != -1:\n",
    "                            images, labels = images.to(args.device), labels.to(args.device)\n",
    "\n",
    "                        outputs = model(images)\n",
    "                        softmax_probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "\n",
    "                        predicted_labels = torch.argmax(softmax_probs, dim=1)\n",
    "\n",
    "                        for i in range(len(labels)):\n",
    "                            label = labels[i].item()\n",
    "                            predicted_label = predicted_labels[i].item()\n",
    "                            prob_vector = softmax_probs[i]\n",
    "\n",
    "                            if predicted_label == label:\n",
    "                                # 예측 성공한 경우\n",
    "                                success_counts[label] += 1\n",
    "                                success_prob_sums[label] += prob_vector\n",
    "                                accuracies[label] += 1\n",
    "                            else:\n",
    "                                # 예측 실패한 경우\n",
    "                                failure_counts[label] += 1\n",
    "                                failure_prob_sums[label] += prob_vector\n",
    "\n",
    "\n",
    "            # 클래스별로 평균 softmax 확률 벡터를 계산합니다.\n",
    "            success_prob_vectors = [success_prob_sums[i] / success_counts[i] for i in range(10)]\n",
    "            failure_prob_vectors = [failure_prob_sums[i] / failure_counts[i] for i in range(10)]\n",
    "            classwise_accuracy=[]\n",
    "\n",
    "            # 결과 출력\n",
    "            for i in range(10):\n",
    "                print(f\"Class {i+1} - Accuracy: {success_counts[i]/(success_counts[i]+failure_counts[i]):.2%}\")\n",
    "                classwise_accuracy.append(success_counts[i]/(success_counts[i]+failure_counts[i]))\n",
    "                print(\"Success Probability Vector:\")\n",
    "                print(success_prob_vectors[i])\n",
    "                print(\"Failure Probability Vector:\")\n",
    "                print(failure_prob_vectors[i])\n",
    "        print(classwise_accuracy)\n",
    "        print(sum(classwise_accuracy) / len(classwise_accuracy))\n",
    "        print(calculate_variance(classwise_accuracy))\n",
    "        print(success_counts) \n",
    "        print(failure_counts) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedfn",
   "language": "python",
   "name": "fedfn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
